{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff2f28d-abd0-480f-88a3-4334ef6367d9",
   "metadata": {},
   "source": [
    "# Notebook to build workflow into a SageMaker Pipeline\n",
    "\n",
    "In this notebook, we show how to create a SageMaker Pipeline in two ways:\n",
    "1. Creating a single pipeline step with the entire RAG creation and testing workflow\n",
    "2. Creating a multi-step pipline with each step of the process as a separate job.\n",
    "\n",
    "To familiarize yourself with the RAG building process, run through the [Experimentation Notebook](./sagemaker-mlflow-experiment-agenticrag.ipynb) before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f73a8f-3afd-45d1-9b8e-5384165d1ccd",
   "metadata": {},
   "source": [
    "## Option 1: Create a single step with the entire end-to-end workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f970eb8-f578-4942-9743-7774e0e89e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:10:02.234450Z",
     "iopub.status.busy": "2025-06-25T19:10:02.233898Z",
     "iopub.status.idle": "2025-06-25T19:10:02.239104Z",
     "shell.execute_reply": "2025-06-25T19:10:02.238170Z",
     "shell.execute_reply.started": "2025-06-25T19:10:02.234422Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d11e8-433c-4302-8a4d-a6eefc01f2ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:10:02.365978Z",
     "iopub.status.busy": "2025-06-25T19:10:02.365414Z",
     "iopub.status.idle": "2025-06-25T19:10:02.768820Z",
     "shell.execute_reply": "2025-06-25T19:10:02.768064Z",
     "shell.execute_reply.started": "2025-06-25T19:10:02.365951Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize SageMaker session\n",
    "session = sagemaker.Session()\n",
    "region = session.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = session.default_bucket()\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "print(f\"SageMaker Role ARN: {role}\")\n",
    "print(f\"SageMaker Session Region: {region}\")\n",
    "print(f\"SageMaker Session Default Bucket: {default_bucket}\")\n",
    "\n",
    "# Output S3 location\n",
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "output_s3_uri = f\"s3://{default_bucket}/rag-pipeline/output/{timestamp}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1ee83-25af-4171-a390-c0595d1abb7b",
   "metadata": {},
   "source": [
    "### Arguments for Processing Job (Replace with your own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a0774e-fc4d-40e2-9217-8f6043ea3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_tracking_uri = \"\" #  REPLACE WITH YOUR OWN \n",
    "embedding_endpoint_name = \"rag-embeddings-endpoint\"  \n",
    "text_endpoint_name = \"rag-generation-endpoint\"  \n",
    "domain_name = \"\" #REPLACE WITH YOUR OWN (example: \"search-ragops-testing-xxxxxxx.us-west-2.es.amazonaws.com\")\n",
    "index_name = \"ragops-exp-index-1\"\n",
    "model_dimensions = \"384\"\n",
    "\n",
    "prefix = \"rag-pipeline\"\n",
    "experiment_name = f\"rag-pipeline-{timestamp}\"\n",
    "parent_run_name = \"rag-experiment-test\"\n",
    "\n",
    "embedding_model_id = \"huggingface-textembedding-all-MiniLM-L6-v2\"\n",
    "text_model_id = \"deepseek-llm-r1-distill-qwen-7b\"\n",
    "\n",
    "chunking_strategy = \"RecursiveChunker\"\n",
    "chunk_size = \"500\"\n",
    "chunk_overlap = \"200\"\n",
    "\n",
    "context_retrieval_size = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1aa51d-c547-4d30-99d4-bd2e74d6afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your existing script\n",
    "script_path = \"single-step-pipeline.py\"  \n",
    "source_dir = '../sagemaker_pipeline/single_step_pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff66551-6cbc-4b72-a04b-716f000db806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:10:02.771955Z",
     "iopub.status.busy": "2025-06-25T19:10:02.771539Z",
     "iopub.status.idle": "2025-06-25T19:10:02.822295Z",
     "shell.execute_reply": "2025-06-25T19:10:02.821220Z",
     "shell.execute_reply.started": "2025-06-25T19:10:02.771927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the processor\n",
    "processor = PyTorchProcessor(\n",
    "    framework_version=\"2.5\",\n",
    "    role=role,\n",
    "    py_version=\"py311\",\n",
    "    instance_type=\"ml.m5.4xlarge\",  \n",
    "    instance_count=1,\n",
    "    base_job_name=\"rag-pipeline\",\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "job_name = f\"rag-pipeline-{timestamp}\"\n",
    "processing_step_args = processor.run(\n",
    "    code=script_path,\n",
    "    source_dir=source_dir,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"rag_output\",\n",
    "            source=\"/opt/ml/processing/output/\",\n",
    "            destination=output_s3_uri\n",
    "        )\n",
    "    ],\n",
    "    arguments=[\n",
    "        \"--experiment-name\", experiment_name,\n",
    "        \"--mlflow-tracking-uri\", mlflow_tracking_uri,\n",
    "        \"--embedding-endpoint-name\", embedding_endpoint_name,\n",
    "        \"--text-endpoint-name\", text_endpoint_name,\n",
    "        \"--domain-name\", domain_name,\n",
    "        \"--index-name\", index_name,\n",
    "        \"--chunking-strategy\", chunking_strategy,\n",
    "        \"--chunk-size\", chunk_size,\n",
    "        \"--chunk-overlap\", chunk_overlap,\n",
    "        \"--context-retrieval-size\", context_retrieval_size,\n",
    "        \"--embedding-model-id\", embedding_model_id,\n",
    "        \"--text-model-id\", text_model_id,\n",
    "        \"--output-data-path\", \"/opt/ml/processing/output\",\n",
    "        \"--role-arn\", role\n",
    "    ],\n",
    "    logs=True   \n",
    ")\n",
    "\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name=\"PreprocessingStep\",\n",
    "    step_args=processing_step_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307e216-ae71-4465-9cdd-0554bc3b6156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:10:03.665629Z",
     "iopub.status.busy": "2025-06-25T19:10:03.665234Z",
     "iopub.status.idle": "2025-06-25T19:10:03.703681Z",
     "shell.execute_reply": "2025-06-25T19:10:03.702320Z",
     "shell.execute_reply.started": "2025-06-25T19:10:03.665605Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=\"rag-evalution-test\",\n",
    "    steps=[\n",
    "        processing_step\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cda34e-3cf0-4bc0-9017-7b728a594ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:10:04.502036Z",
     "iopub.status.busy": "2025-06-25T19:10:04.501599Z",
     "iopub.status.idle": "2025-06-25T19:10:05.688094Z",
     "shell.execute_reply": "2025-06-25T19:10:05.687149Z",
     "shell.execute_reply.started": "2025-06-25T19:10:04.502006Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6537d5c9-b567-4d87-9e43-c105df03fad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:10:06.358067Z",
     "iopub.status.busy": "2025-06-25T19:10:06.357672Z",
     "iopub.status.idle": "2025-06-25T19:10:06.805800Z",
     "shell.execute_reply": "2025-06-25T19:10:06.804992Z",
     "shell.execute_reply.started": "2025-06-25T19:10:06.358043Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_execution = pipeline.start()\n",
    "pipeline_execution.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650fd29-4e46-4508-8b05-5bee8f957a76",
   "metadata": {},
   "source": [
    "## Option 2: Create separate pipeline steps for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5a423-0be3-4e16-8935-4d6c2c4d58c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:24:10.128042Z",
     "iopub.status.busy": "2025-06-25T19:24:10.127628Z",
     "iopub.status.idle": "2025-06-25T19:24:10.236247Z",
     "shell.execute_reply": "2025-06-25T19:24:10.235197Z",
     "shell.execute_reply.started": "2025-06-25T19:24:10.128015Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.pytorch.processing import PyTorchProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Setup\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "pipeline_session = sagemaker.workflow.pipeline_context.PipelineSession()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1e6c9-faf8-4320-a14e-421ff728baef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:24:10.484962Z",
     "iopub.status.busy": "2025-06-25T19:24:10.484640Z",
     "iopub.status.idle": "2025-06-25T19:24:10.765763Z",
     "shell.execute_reply": "2025-06-25T19:24:10.764592Z",
     "shell.execute_reply.started": "2025-06-25T19:24:10.484938Z"
    }
   },
   "outputs": [],
   "source": [
    "default_bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Output S3 location\n",
    "timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "output_s3_uri = f\"s3://{default_bucket}/rag-pipeline/output/{timestamp}/\"\n",
    "\n",
    "\n",
    "# S3 paths\n",
    "base_s3_uri = f\"s3://{default_bucket}/{prefix}/{timestamp}\"\n",
    "data_prep_output_s3_uri = f\"{base_s3_uri}/data-prep\"\n",
    "chunking_output_s3_uri = f\"{base_s3_uri}/chunking\"\n",
    "ingestion_output_s3_uri = f\"{base_s3_uri}/ingestion\"\n",
    "retrieval_output_s3_uri = f\"{base_s3_uri}/retrieval\"\n",
    "evaluation_output_s3_uri = f\"{base_s3_uri}/evaluation\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e2079c-38ce-42a0-bfbc-ca822a0c13bb",
   "metadata": {},
   "source": [
    "### Arguments for Processing Job (Replace with your own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf7697-663c-45b7-94e2-e104a915027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_tracking_uri = \"\" #REPLACE WITH YOUR OWN  \n",
    "embedding_endpoint_name = \"rag-embeddings-endpoint\"  \n",
    "text_endpoint_name = \"rag-generation-endpoint\"  \n",
    "domain_name = \"\" #REPLACE WITH YOUR OWN (example: \"search-ragops-testing-xxxxxxx.us-west-2.es.amazonaws.com\")\n",
    "index_name = \"ragops-exp-index-1\"\n",
    "model_dimensions = \"384\"\n",
    "\n",
    "prefix = \"rag-pipeline\"\n",
    "experiment_name = f\"rag-pipeline-{timestamp}\"\n",
    "parent_run_name = \"rag-experiment-test\"\n",
    "\n",
    "embedding_model_id = \"huggingface-textembedding-all-MiniLM-L6-v2\"\n",
    "text_model_id = \"deepseek-llm-r1-distill-qwen-7b\"\n",
    "\n",
    "chunking_strategy = \"RecursiveChunker\"\n",
    "chunk_size = \"500\"\n",
    "chunk_overlap = \"200\"\n",
    "\n",
    "context_retrieval_size = \"3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046b6a3-b672-4837-afd7-aa876d248791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder of scripts\n",
    "script_path = \"../sagemaker_pipeline/multi_step_pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edcf674-8bb6-43bc-b281-8cff12f81703",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T19:09:58.354917Z",
     "iopub.status.busy": "2025-06-25T19:09:58.354630Z",
     "iopub.status.idle": "2025-06-25T19:09:58.419967Z",
     "shell.execute_reply": "2025-06-25T19:09:58.419053Z",
     "shell.execute_reply.started": "2025-06-25T19:09:58.354896Z"
    }
   },
   "outputs": [],
   "source": [
    "processor = PyTorchProcessor(\n",
    "    framework_version=\"2.5\",\n",
    "    role=role,\n",
    "    py_version=\"py311\",\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"rag-pipeline\",\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "data_prep_step_args = processor.run(\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"data_prep_output\",\n",
    "            source=\"/opt/ml/processing/output/\",\n",
    "            destination=data_prep_output_s3_uri\n",
    "        )\n",
    "    ],\n",
    "    code=\"data_preparation.py\",\n",
    "    source_dir=script_path,\n",
    "    arguments=[\n",
    "        \"--experiment-name\", experiment_name,\n",
    "        \"--mlflow-tracking-uri\", mlflow_tracking_uri,\n",
    "        \"--output-data-path\", \"/opt/ml/processing/output\",\n",
    "        \"--parent-run-name\", parent_run_name\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_prep_step = ProcessingStep(\n",
    "    name=\"DataPrepStep\",\n",
    "    step_args=data_prep_step_args\n",
    ")\n",
    "\n",
    "\n",
    "# Step 2: Data Chunking\n",
    "chunking_step_args = processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=data_prep_step.properties.ProcessingOutputConfig.Outputs[\"data_prep_output\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"chunking_output\",\n",
    "            source=\"/opt/ml/processing/output/\",\n",
    "            destination=chunking_output_s3_uri\n",
    "        )\n",
    "    ],\n",
    "    code=\"data_chunking.py\",\n",
    "    source_dir=script_path,\n",
    "    arguments=[\n",
    "        \"--experiment-name\", experiment_name,\n",
    "        \"--mlflow-tracking-uri\", mlflow_tracking_uri,\n",
    "        \"--input-data-path\", \"/opt/ml/processing/input\",\n",
    "        \"--output-data-path\", \"/opt/ml/processing/output\",\n",
    "        \"--chunking-strategy\", chunking_strategy,\n",
    "        \"--chunk-size\", chunk_size,\n",
    "        \"--chunk-overlap\", chunk_overlap\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_chunking_step = ProcessingStep(\n",
    "    name=\"DataChunkingStep\",\n",
    "    step_args=chunking_step_args\n",
    ")\n",
    "\n",
    "\n",
    "# Step 3: Data Ingestion\n",
    "ingestion_step_args = processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=data_chunking_step.properties.ProcessingOutputConfig.Outputs[\"chunking_output\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"ingestion_output\",\n",
    "            source=\"/opt/ml/processing/output/\",\n",
    "            destination=ingestion_output_s3_uri\n",
    "        )\n",
    "    ],\n",
    "    code=\"data_ingestion.py\",\n",
    "    source_dir=script_path,\n",
    "    arguments=[\n",
    "        \"--experiment-name\", experiment_name,\n",
    "        \"--mlflow-tracking-uri\", mlflow_tracking_uri,\n",
    "        \"--input-data-path\", \"/opt/ml/processing/input\",\n",
    "        \"--output-data-path\", \"/opt/ml/processing/output\",\n",
    "        \"--embedding-endpoint-name\", embedding_endpoint_name,\n",
    "        \"--domain-name\", domain_name,\n",
    "        \"--index-name\", index_name,\n",
    "        \"--model-dimensions\", model_dimensions,\n",
    "        \"--embedding-model-id\", embedding_model_id\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_ingestion_step = ProcessingStep(\n",
    "    name=\"DataIngestionStep\",\n",
    "    step_args=ingestion_step_args\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: RAG Retrieval\n",
    "retrieval_step_args = processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=data_ingestion_step.properties.ProcessingOutputConfig.Outputs[\"ingestion_output\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"retrieval_output\",\n",
    "            source=\"/opt/ml/processing/output/\",\n",
    "            destination=retrieval_output_s3_uri\n",
    "        )\n",
    "    ],\n",
    "    code=\"rag_retrieval.py\",\n",
    "    source_dir=script_path,\n",
    "    arguments=[\n",
    "        \"--experiment-name\", experiment_name,\n",
    "        \"--mlflow-tracking-uri\", mlflow_tracking_uri,\n",
    "        \"--input-data-path\", \"/opt/ml/processing/input\",\n",
    "        \"--output-data-path\", \"/opt/ml/processing/output\",\n",
    "        \"--embedding-endpoint-name\", embedding_endpoint_name,\n",
    "        \"--text-endpoint-name\", text_endpoint_name,\n",
    "        \"--domain-name\", domain_name,\n",
    "        \"--index-name\", index_name,\n",
    "        \"--context-retrieval-size\", context_retrieval_size,\n",
    "        \"--embedding-model-id\", embedding_model_id,\n",
    "        \"--text-model-id\", text_model_id\n",
    "    ]\n",
    ")\n",
    "\n",
    "rag_retrieval_step = ProcessingStep(\n",
    "    name=\"RAGRetrievalStep\",\n",
    "    step_args=retrieval_step_args\n",
    ")\n",
    "\n",
    "\n",
    "# Step 5: RAG Evaluation\n",
    "evaluation_step_args = processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=rag_retrieval_step.properties.ProcessingOutputConfig.Outputs[\"retrieval_output\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation_output\",\n",
    "            source=\"/opt/ml/processing/output/\",\n",
    "            destination=evaluation_output_s3_uri\n",
    "        )\n",
    "    ],\n",
    "    code=\"rag_evaluation.py\",\n",
    "    source_dir=script_path,\n",
    "    arguments=[\n",
    "        \"--experiment-name\", experiment_name,\n",
    "        \"--mlflow-tracking-uri\", mlflow_tracking_uri,\n",
    "        \"--input-data-path\", \"/opt/ml/processing/input\",\n",
    "        \"--output-data-path\", \"/opt/ml/processing/output\",\n",
    "        \"--embedding-endpoint-name\", embedding_endpoint_name,\n",
    "        \"--text-endpoint-name\", text_endpoint_name,\n",
    "        \"--domain-name\", domain_name,\n",
    "        \"--embedding-model-id\", embedding_model_id,\n",
    "        \"--text-model-id\", text_model_id,\n",
    "        \"--chunking-strategy\", chunking_strategy,\n",
    "        \"--chunk-size\", chunk_size,\n",
    "        \"--chunk-overlap\", chunk_overlap,\n",
    "        \"--role-arn\", role\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "rag_evaluation_step = ProcessingStep(\n",
    "    name=\"RAGEvaluationStep\",\n",
    "    step_args=evaluation_step_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a93035-ba6a-4710-8963-652c71dfcbda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T17:15:46.646820Z",
     "iopub.status.busy": "2025-06-25T17:15:46.646401Z",
     "iopub.status.idle": "2025-06-25T17:15:46.655087Z",
     "shell.execute_reply": "2025-06-25T17:15:46.654129Z",
     "shell.execute_reply.started": "2025-06-25T17:15:46.646790Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=f\"RAGPipeline-{timestamp}\",\n",
    "    steps=[data_prep_step, data_chunking_step, data_ingestion_step, rag_retrieval_step, rag_evaluation_step],\n",
    "    sagemaker_session=pipeline_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e0c698-4a89-421c-8bc6-79e661f18134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T17:15:46.812545Z",
     "iopub.status.busy": "2025-06-25T17:15:46.812046Z",
     "iopub.status.idle": "2025-06-25T17:15:48.180089Z",
     "shell.execute_reply": "2025-06-25T17:15:48.179179Z",
     "shell.execute_reply.started": "2025-06-25T17:15:46.812514Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12215486-786f-491b-9f75-cc8e6f79823e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T17:15:48.182258Z",
     "iopub.status.busy": "2025-06-25T17:15:48.181656Z",
     "iopub.status.idle": "2025-06-25T17:15:48.366579Z",
     "shell.execute_reply": "2025-06-25T17:15:48.365930Z",
     "shell.execute_reply.started": "2025-06-25T17:15:48.182223Z"
    }
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start()\n",
    "print(f\"Pipeline execution started with ARN: {execution.arn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
